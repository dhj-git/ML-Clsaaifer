{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "model_save_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/desiontree\"  #名字\n",
    "train_data_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/train1.txt\"\n",
    "validate_data_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/dev1.txt\"\n",
    "test_data_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/test1.txt\"\n",
    "test_data_predict_out_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import json\n",
    "\n",
    "label2id = {'happy': 0, 'angry': 1, 'sad': 2, 'fear': 3, 'surprise': 4, 'neutral': 5}\n",
    "def load_data(filename):\n",
    "    D = []\n",
    "    f = json.load(open(filename))    \n",
    "    for l in f:\n",
    "        label, content = label2id[l['label']],l['content']\n",
    "        D.append((label, content))\n",
    "    return D\n",
    "\n",
    "# 分词\n",
    "def seg_words(contents):\n",
    "    contents_segs = list()\n",
    "    for content in contents:\n",
    "        segs = jieba.lcut(content[1])\n",
    "        # print(segs)\n",
    "        contents_segs.append(\" \".join(segs))\n",
    "\n",
    "    return contents_segs\n",
    "# content_train = load_data(train_data_path)\n",
    "# s = seg_words(content_train)\n",
    "# # print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] <%(processName)s> (%(threadName)s) %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TextClassifier():\n",
    "\n",
    "    def __init__(self, vectorizer, classifier=MultinomialNB()):\n",
    "        classifier = SVC(kernel=\"rbf\")\n",
    "        # classifier = KNeighborsClassifier(6, weights='uniform')\n",
    "        # classifier = DecisionTreeClassifier()\n",
    "\n",
    "        # classifier = SVC(kernel=\"linear\")\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def features(self, x):\n",
    "        return self.vectorizer.transform(x)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "        self.classifier.fit(self.features(x), y)\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        return self.classifier.predict(self.features(x))\n",
    "\n",
    "    def score(self, x, y):\n",
    "        return self.classifier.score(self.features(x), y)\n",
    "\n",
    "    def get_f1_score(self, x, y):\n",
    "        return f1_score(y, self.predict(x), average='macro')\n",
    "    \n",
    "    def get_acc_score(self, x, y):\n",
    "        return accuracy_score(y, self.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "import logging\n",
    "import argparse\n",
    "import joblib\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] <%(processName)s> (%(threadName)s) %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    model_name = \"model_dict.pkl\"\n",
    "\n",
    "    # load data\n",
    "    logger.info(\"start load data\")\n",
    "    content_test = load_data(test_data_path)\n",
    "\n",
    "    # load model\n",
    "    logger.info(\"start load model\")\n",
    "    classifier_dict = joblib.load(model_save_path + model_name)\n",
    "    # print(classifier_dict)\n",
    "    labels_test = []\n",
    "    for l in content_test:\n",
    "        labels_test.append(l[0])\n",
    "    # seg words\n",
    "    logger.info(\"start seg test data\")\n",
    "    content_test = seg_words(content_test)\n",
    "    logger.info(\"complete seg test data\")\n",
    "    \n",
    "    # model predict\n",
    "    logger.info(\"start predict test data\")\n",
    "\n",
    "\n",
    "    # test_data_df= classifier_dict.predict(content_test)\n",
    "    f1_score = classifier_dict.get_f1_score(content_test, labels_test)\n",
    "    acc_score = classifier_dict.get_acc_score(content_test, labels_test)\n",
    "    \n",
    "    # test_data_df.to_csv(test_data_predict_out_path, encoding=\"utf_8_sig\", index=False)\n",
    "    logger.info(\"compete predict test data\")\n",
    "    logger.info(\"f1_scores: %s\\n\" % f1_score)\n",
    "    logger.info(\"acc_score: %s\" % acc_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
