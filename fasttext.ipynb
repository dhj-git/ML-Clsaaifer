{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "model_save_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/fasttext\"  #名字\n",
    "train_data_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/train1.txt\"\n",
    "validate_data_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/dev1.txt\"\n",
    "test_data_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/test1.txt\"\n",
    "test_data_predict_out_path = \"/home/sys1/Dong/A_Stage_Two/ABSA-QUAD/data/clean/uausal/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import json\n",
    "\n",
    "label2id = {'happy': 0, 'angry': 1, 'sad': 2, 'fear': 3, 'surprise': 4, 'neutral': 5}\n",
    "def load_data(filename):\n",
    "    D = []\n",
    "    f = json.load(open(filename))    \n",
    "    for l in f:\n",
    "        label, content = label2id[l['label']],l['content']\n",
    "        D.append((label, content))\n",
    "    return D\n",
    "\n",
    "# 分词\n",
    "def seg_words(contents):\n",
    "    contents_segs = list()\n",
    "    for content in contents:\n",
    "        segs = jieba.lcut(content[1])\n",
    "        # print(segs)\n",
    "        contents_segs.append(\" \".join(segs))\n",
    "\n",
    "    return contents_segs\n",
    "# content_train = load_data(train_data_path)\n",
    "# s = seg_words(content_train)\n",
    "# # print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 19:49:12,561 [INFO] <MainProcess> (MainThread) start load load\n",
      "2023-03-27 19:49:12,653 [INFO] <MainProcess> (MainThread) start seg train data\n",
      "Building prefix dict from the default dictionary ...\n",
      "2023-03-27 19:49:12,654 [DEBUG] <MainProcess> (MainThread) Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "2023-03-27 19:49:12,656 [DEBUG] <MainProcess> (MainThread) Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.652 seconds.\n",
      "2023-03-27 19:49:13,308 [DEBUG] <MainProcess> (MainThread) Loading model cost 0.652 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2023-03-27 19:49:13,311 [DEBUG] <MainProcess> (MainThread) Prefix dict has been built successfully.\n",
      "2023-03-27 19:49:18,418 [INFO] <MainProcess> (MainThread) complete seg train data\n",
      "2023-03-27 19:49:18,421 [INFO] <MainProcess> (MainThread) prepare train format\n",
      "2023-03-27 19:49:18,449 [INFO] <MainProcess> (MainThread) complete formate train data\n",
      "2023-03-27 19:49:18,450 [INFO] <MainProcess> (MainThread) start train model\n",
      "Read 0M words\n",
      "Number of words:  63918\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread:  344608 lr:  0.000000 avg.loss:  0.562107 ETA:   0h 0m 0s\n",
      "2023-03-27 19:49:19,414 [INFO] <MainProcess> (MainThread) complete train model\n",
      "2023-03-27 19:49:19,415 [INFO] <MainProcess> (MainThread) start save model\n",
      "2023-03-27 19:49:19,498 [INFO] <MainProcess> (MainThread) complete svae model\n",
      "2023-03-27 19:49:19,507 [INFO] <MainProcess> (MainThread) start seg validata data\n",
      "2023-03-27 19:49:19,881 [INFO] <MainProcess> (MainThread) complet seg validata data\n",
      "2023-03-27 19:49:19,883 [INFO] <MainProcess> (MainThread) prepare valid format\n",
      "2023-03-27 19:49:19,884 [INFO] <MainProcess> (MainThread) complete formate train data\n",
      "2023-03-27 19:49:19,885 [INFO] <MainProcess> (MainThread) start compute f1 score for validata model\n",
      "2023-03-27 19:49:19,917 [INFO] <MainProcess> (MainThread) acc: 0.695\n",
      "\n",
      "2023-03-27 19:49:19,918 [INFO] <MainProcess> (MainThread) f1_score: 0.6617480482392255\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from skift import FirstColFtClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] <%(processName)s> (%(threadName)s) %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    model_name = 'fasttext_model.pkl'\n",
    "    learning_rate = 1.0\n",
    "    epoch = 10\n",
    "    word_ngrams = 1\n",
    "    min_count = 1\n",
    "\n",
    "    # load train data\n",
    "    logger.info(\"start load load\")\n",
    "    content_train = load_data(train_data_path)\n",
    "    \n",
    "\n",
    "    labels_train = []\n",
    "    for l in content_train:\n",
    "        labels_train .append(l[0])\n",
    "\n",
    "    logger.info(\"start seg train data\")\n",
    "    content_train = seg_words(content_train)\n",
    "    logger.info(\"complete seg train data\")\n",
    "\n",
    "    logger.info(\"prepare train format\")\n",
    "    train_data_format = np.asarray([content_train]).T\n",
    "    logger.info(\"complete formate train data\")\n",
    "\n",
    "\n",
    "\n",
    "    # model train\n",
    "    logger.info(\"start train model\")\n",
    "    \n",
    "    \n",
    "    sk_clf = FirstColFtClassifier(lr=learning_rate, epoch=epoch,\n",
    "                                    wordNgrams=word_ngrams,\n",
    "                                    minCount=min_count, verbose=2)\n",
    "    sk_clf.fit(train_data_format, labels_train)\n",
    "    classifier_dict = sk_clf\n",
    "\n",
    "    logger.info(\"complete train model\")\n",
    "    logger.info(\"start save model\")\n",
    "    model_path = model_save_path\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    joblib.dump(classifier_dict, model_path + model_name)\n",
    "    logger.info(\"complete svae model\")\n",
    "\n",
    "    # validata model\n",
    "    content_validata = load_data(validate_data_path)\n",
    "    labels_validate = []\n",
    "    for l in content_validata:\n",
    "        labels_validate .append(l[0])\n",
    "\n",
    "    logger.info(\"start seg validata data\")\n",
    "    content_validata = seg_words(content_validata)\n",
    "    logger.info(\"complet seg validata data\")\n",
    "\n",
    "    logger.info(\"prepare valid format\")\n",
    "    validata_data_format = np.asarray([content_validata]).T\n",
    "    logger.info(\"complete formate train data\")\n",
    "\n",
    "    logger.info(\"start compute f1 score for validata model\")\n",
    "    \n",
    "    true_label = np.asarray(labels_validate)\n",
    "    classifier = classifier_dict\n",
    "    pred_label = classifier.predict(validata_data_format).astype(int)\n",
    "    f1_score1 = f1_score(true_label, pred_label,average='macro')\n",
    "    acc = accuracy_score(true_label, pred_label)\n",
    "\n",
    "    logger.info(\"acc: %s\\n\" % acc)\n",
    "    logger.info(\"f1_score: %s\" % f1_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 19:51:13,419 [INFO] <MainProcess> (MainThread) start load load\n",
      "2023-03-27 19:51:13,440 [INFO] <MainProcess> (MainThread) start load model\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "2023-03-27 19:51:13,534 [INFO] <MainProcess> (MainThread) start seg train data\n",
      "2023-03-27 19:51:14,476 [INFO] <MainProcess> (MainThread) complete seg train data\n",
      "2023-03-27 19:51:14,478 [INFO] <MainProcess> (MainThread) prepare predict data format\n",
      "2023-03-27 19:51:14,482 [INFO] <MainProcess> (MainThread) complete prepare predict formate data\n",
      "2023-03-27 19:51:14,484 [INFO] <MainProcess> (MainThread) start predict test data\n",
      "2023-03-27 19:51:14,560 [INFO] <MainProcess> (MainThread) complete predict test data\n",
      "2023-03-27 19:51:14,561 [INFO] <MainProcess> (MainThread) acc: 0.6918\n",
      "\n",
      "2023-03-27 19:51:14,562 [INFO] <MainProcess> (MainThread) f1_score: 0.6587498749380203\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] <%(processName)s> (%(threadName)s) %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    model_name = 'fasttext_model.pkl'\n",
    "\n",
    "    # load data\n",
    "    logger.info(\"start load load\")\n",
    "    content_test = load_data(test_data_path)\n",
    "    labels_test = []\n",
    "    for l in content_test:\n",
    "        labels_test.append(l[0])\n",
    "    # load model\n",
    "    logger.info(\"start load model\")\n",
    "    classifier_dict = joblib.load(model_path + model_name)\n",
    "\n",
    "    logger.info(\"start seg train data\")\n",
    "    content_test = seg_words(content_test)\n",
    "    logger.info(\"complete seg train data\")\n",
    "\n",
    "    logger.info(\"prepare predict data format\")\n",
    "    test_data_format = np.asarray([content_test]).T\n",
    "    logger.info(\"complete prepare predict formate data\")\n",
    "\n",
    "    true_label = np.asarray(labels_test)\n",
    "    # model predict\n",
    "    logger.info(\"start predict test data\")\n",
    "    test_pre = classifier_dict.predict(test_data_format).astype(int)\n",
    "    \n",
    "    f1_score1 = f1_score(true_label, test_pre,average='macro')\n",
    "    acc = accuracy_score(true_label, test_pre)\n",
    "    \n",
    "    logger.info(\"complete predict test data\")\n",
    "    logger.info(\"acc: %s\\n\" % acc)\n",
    "    logger.info(\"f1_score: %s\" % f1_score1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dong_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
